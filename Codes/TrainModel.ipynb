{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "import io\n",
    "import contextlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import  f1_score, mean_squared_error, r2_score, make_scorer, accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import pearsonr\n",
    "from xgboost.callback import EarlyStopping\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_DAYS = 10\n",
    "PAST_DAYS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change these two to change models\n",
    "pm25 = False\n",
    "improvement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_prefix = '../Models/saved_models'\n",
    "folder_suffix = [\n",
    "    'yes_pm25' if pm25 else 'no_pm25',\n",
    "    'yes_improvement' if improvement else 'no_improvement'\n",
    "]\n",
    "models_folder = f\"{folder_prefix}_{'_'.join(folder_suffix)}\"\n",
    "\n",
    "models_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Inputs/data_onkk.csv')\n",
    "population_data = pd.read_excel('../Inputs/population_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, population_data, on='SID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time'] = pd.to_datetime(data['time'], format='%m/%d/%Y')\n",
    "data['day'] = data['time'].dt.day\n",
    "data['month'] = data['time'].dt.month\n",
    "data['year'] = data['time'].dt.year\n",
    "\n",
    "data = data.sort_values(by=['SID', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Autumn'\n",
    "\n",
    "def feature_engineering(df):\n",
    "    if not improvement:\n",
    "        return df\n",
    "\n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "    df['diffusion_conditions'] = df['WSPD'] * df['TP']\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_features = ['WSPD', 'WDIR', 'TMP', 'TX', 'TN', 'TP', 'RH', 'PRES2M']\n",
    "\n",
    "if improvement:\n",
    "    lag_features += ['diffusion_conditions']\n",
    "\n",
    "if pm25:\n",
    "    lag_features += ['pm25']\n",
    "\n",
    "for lag in range(1, PAST_DAYS + 1):\n",
    "    data[f'time_lag_{lag}'] = data['time'] - pd.Timedelta(days=lag)\n",
    "    for feature in lag_features: \n",
    "        data = data.merge(\n",
    "            data[['SID', 'time', feature]].rename(columns={'time': f'time_lag_{lag}', feature: f'{feature}_lag_{lag}'}),\n",
    "            on=['SID', f'time_lag_{lag}'], how='left'\n",
    "        )\n",
    "\n",
    "    data = data.drop(columns=[f'time_lag_{lag}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(0, N_DAYS):\n",
    "    data[f'time_target_{day}'] = data['time'] + pd.Timedelta(days=day)\n",
    "    data = data.merge(\n",
    "        data[['SID', 'time', 'pm25']].rename(columns={'time': f'time_target_{day}', 'pm25': f'pm25_target_{day}'}),\n",
    "        on=['SID', f'time_target_{day}'], how='left'\n",
    "    )\n",
    "    data = data.drop(columns=[f'time_target_{day}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[f'pm25_target_{day}' for day in range(0, N_DAYS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm25_to_aqi(pm25):\n",
    "    bp = [\n",
    "        (0, 25, 0, 50),\n",
    "        (25, 50, 51, 100),\n",
    "        (50, 80, 101, 150),\n",
    "        (80, 150, 151, 200),\n",
    "        (150, 250, 201, 300),\n",
    "        (250, 350, 301, 400),\n",
    "        (350, 500, 401, 500),\n",
    "        (500, float('inf'), 501, 500) \n",
    "    ]\n",
    "    for (bp_low, bp_high, i_low, i_high) in bp:\n",
    "        if bp_low <= pm25 < bp_high:\n",
    "            aqi = ((i_high - i_low) / (bp_high - bp_low)) * (pm25 - bp_low) + i_low\n",
    "            return min(round(aqi), i_high) \n",
    "    return 500\n",
    "\n",
    "def aqi_category(aqi):\n",
    "    if aqi <= 50:\n",
    "        return 0 \n",
    "    elif 51 <= aqi <= 100:\n",
    "        return 1 \n",
    "    elif 101 <= aqi <= 150:\n",
    "        return 2 \n",
    "    elif 151 <= aqi <= 200:\n",
    "        return 3 \n",
    "    elif 201 <= aqi <= 300:\n",
    "        return 4 \n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "vectorized_pm25_to_aqi = np.vectorize(pm25_to_aqi)\n",
    "vectorized_aqi_category = np.vectorize(aqi_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(0, N_DAYS):\n",
    "    feature = f'pm25_target_{day}'\n",
    "    target = f'AQI_cat_target_{day}'\n",
    "    data[target] = vectorized_pm25_to_aqi(data[feature])\n",
    "    data[target] = vectorized_aqi_category(data[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ([\n",
    "    'SQRT_SEA_DEM_LAT'] +\n",
    "    [f'{feature}_lag_{i}' for feature in lag_features for i in range(1, PAST_DAYS + 1)]\n",
    ")\n",
    "\n",
    "if improvement:\n",
    "    features += ['urbanization_rate', 'population_density', 'season']\n",
    "\n",
    "targets = [f'AQI_cat_target_{day}' for day in range(0, N_DAYS)]\n",
    "\n",
    "X = data[features]\n",
    "y = data[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time = (data['time'] >= '2021-06-01') & (data['time'] <= '2021-12-31')\n",
    "\n",
    "X_test = X.loc[test_time]\n",
    "y_test = y.loc[test_time]\n",
    "\n",
    "X_train_full = X.loc[~test_time]\n",
    "y_train_full = y.loc[~test_time]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.25,\n",
    "    random_state=SEED,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "total_samples = X.shape[0]\n",
    "\n",
    "splits = {\n",
    "    \"Train\": X_train,\n",
    "    \"Validation\": X_valid,\n",
    "    \"Test\": X_test\n",
    "}\n",
    "\n",
    "for name, X_split in splits.items():\n",
    "    n = X_split.shape[0]\n",
    "    pct = n / total_samples * 100\n",
    "    print(f\"{name} samples: {n} ({pct:.2f}% of total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X_train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "    X_test[col] = label_encoder.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_valid = pd.DataFrame(X_valid, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 10000,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1,  \n",
    "    'reg_lambda': 5,\n",
    "    'random_state': SEED,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda'\n",
    "}\n",
    "\n",
    "LGBM_Params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 10,\n",
    "    'n_estimators': 10000,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'lambda_l1': 10,  \n",
    "    'lambda_l2': 0.1, \n",
    "    'random_state': SEED,\n",
    "    'device': 'gpu',\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "CatBoost_Params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'depth': 8,\n",
    "    'iterations': 10000,\n",
    "    'random_seed': SEED,\n",
    "    'task_type': 'GPU',\n",
    "    'devices': '0', \n",
    "    'verbose': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_Params.update({ 'eval_metric': 'mlogloss' })\n",
    "LGBM_Params.update({ 'verbosity': -1, 'eval_metric': 'multi_logloss' })\n",
    "CatBoost_Params.update({ 'eval_metric': 'MultiClass' })\n",
    "\n",
    "early_stopping_rounds = 100\n",
    "models_dict = {}\n",
    "\n",
    "for alg in ['CatBoost', 'XGB', 'LGBM']:\n",
    "    print(f\"\\nTraining models for algorithm: {alg}\")\n",
    "    models_per_target = {}\n",
    "    \n",
    "    for target in targets:\n",
    "        print(f\"  Training {alg} model for target: {target}\")\n",
    "        \n",
    "        if alg == 'CatBoost':\n",
    "            model = cb.CatBoostClassifier(**CatBoost_Params)\n",
    "            model.fit(\n",
    "                X_train, y_train[target],\n",
    "                eval_set=(X_valid, y_valid[target]),\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                use_best_model=True,\n",
    "                verbose=False\n",
    "            )\n",
    "            models_per_target[target] = model\n",
    "        \n",
    "        elif alg == 'XGB':\n",
    "            params    = XGB_Params.copy()\n",
    "            num_round = params.pop('n_estimators')\n",
    "            \n",
    "            params.update({\n",
    "                'objective': 'multi:softmax',\n",
    "                'num_class': len(np.unique(y_train[target]))\n",
    "            })\n",
    "            \n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train[target])\n",
    "            dvalid = xgb.DMatrix(X_valid,  label=y_valid[target])\n",
    "            \n",
    "            booster = xgb.train(\n",
    "                params=params,\n",
    "                dtrain=dtrain,\n",
    "                num_boost_round=num_round,\n",
    "                evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                verbose_eval=False\n",
    "            )\n",
    "            models_per_target[target] = booster\n",
    "        \n",
    "        else:  # LGBM\n",
    "            model = lgb.LGBMClassifier(**LGBM_Params)\n",
    "            with contextlib.redirect_stdout(io.StringIO()):\n",
    "                model.fit(\n",
    "                    X_train,\n",
    "                    y_train[target],\n",
    "                    eval_set=[(X_valid, y_valid[target])],\n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(stopping_rounds=early_stopping_rounds),\n",
    "                        lgb.log_evaluation(period=0)\n",
    "                    ]\n",
    "                )\n",
    "            models_per_target[target] = model\n",
    "    \n",
    "    models_dict[alg] = models_per_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputWrapper:\n",
    "    def __init__(self, models, target_list):\n",
    "        self.models = models  \n",
    "        self.targets = target_list\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for target in self.targets:\n",
    "            model = self.models[target]\n",
    "            if isinstance(model, xgb.Booster):\n",
    "                dX = xgb.DMatrix(X)\n",
    "                p = model.predict(dX)\n",
    "            else:\n",
    "                p = model.predict(X)\n",
    "            preds.append(p)\n",
    "        return np.column_stack(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, dataset_name):\n",
    "    y_pred = model.predict(X)\n",
    "    y_true = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    for i, target_name in enumerate(model.targets):\n",
    "        yt = y_true[:, i]\n",
    "        yp = y_pred[:, i]\n",
    "\n",
    "        acc  = accuracy_score(yt, yp)\n",
    "        prec = precision_score(yt, yp, average='weighted', zero_division=0)\n",
    "        rec  = recall_score(yt, yp, average='weighted', zero_division=0)\n",
    "\n",
    "        print(f\"{dataset_name} - {target_name}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg, models in models_dict.items():\n",
    "    wrapped = MultiOutputWrapper(models, targets)\n",
    "    print(f\"\\nEvaluating {alg} on train set\")\n",
    "    evaluate_model(wrapped, X_train, y_train, 'Training')\n",
    "    print(f\"\\nEvaluating {alg} on valid set\")\n",
    "    evaluate_model(wrapped, X_valid, y_valid, 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds_valid = np.column_stack([\n",
    "    models_dict['XGB'][target].predict(xgb.DMatrix(X_valid))\n",
    "    for target in targets\n",
    "])\n",
    "\n",
    "lgbm_preds_valid = np.column_stack([\n",
    "    models_dict['LGBM'][target].predict(X_valid)\n",
    "    for target in targets\n",
    "])\n",
    "\n",
    "catboost_preds_valid = np.column_stack([\n",
    "    models_dict['CatBoost'][target].predict(X_valid)\n",
    "    for target in targets\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_combinations = 10000\n",
    "weights_combinations = np.random.rand(num_combinations, 3)\n",
    "weights_combinations /= np.sum(weights_combinations, axis=1, keepdims=True)\n",
    "\n",
    "initial = np.array([1, 1.5, 2.25, 3.25, 4.5])\n",
    "thresholds_per_day = np.tile(initial, (len(targets), 1))\n",
    "best_weights_list = []\n",
    "\n",
    "def round_with_thresholds(aqi_vals, th):\n",
    "    return np.digitize(aqi_vals, np.sort(th))\n",
    "\n",
    "n_days = len(targets)\n",
    "cols = 3\n",
    "rows = int(np.ceil(n_days / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for day in range(n_days):\n",
    "    best_accuracy = -np.inf\n",
    "\n",
    "    for w in weights_combinations:\n",
    "        raw_pred = (\n",
    "            w[0] * xgb_preds_valid[:, day] +\n",
    "            w[1] * lgbm_preds_valid[:, day] +\n",
    "            w[2] * catboost_preds_valid[:, day]\n",
    "        )\n",
    "        temp_preds = round_with_thresholds(raw_pred, initial)\n",
    "        acc = accuracy_score(y_valid.values[:, day], temp_preds)\n",
    "        if acc > best_accuracy:\n",
    "            best_accuracy = acc\n",
    "            best_w = w.copy()\n",
    "            best_raw_pred = raw_pred.copy()\n",
    "\n",
    "    best_weights_list.append(best_w)\n",
    "    thresholds_per_day[day] = initial \n",
    "\n",
    "    print(\n",
    "        f\"Day {day} ({targets[day]}): \"\n",
    "        f\"Best weights = {[round(v,5) for v in best_w]}, \"\n",
    "        f\"accuracy = {best_accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "    y_true_cat = y_valid.values[:, day]\n",
    "    y_pred_cat = round_with_thresholds(best_raw_pred, initial)\n",
    "    classes = np.unique(np.concatenate([y_true_cat, y_pred_cat]))\n",
    "    cm = confusion_matrix(y_true_cat, y_pred_cat, labels=classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    ax = axes[day]\n",
    "    disp.plot(ax=ax, cmap='Blues', colorbar=True, xticks_rotation='vertical')\n",
    "    ax.set_title(f'Confusion Matrix\\nDay {day}')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "\n",
    "for ax in axes[n_days:]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds_test = np.column_stack([\n",
    "    models_dict['XGB'][target].predict(xgb.DMatrix(X_test))\n",
    "    for target in targets\n",
    "])\n",
    "\n",
    "lgbm_preds_test = np.column_stack([\n",
    "    models_dict['LGBM'][target].predict(X_test)\n",
    "    for target in targets\n",
    "])\n",
    "\n",
    "catboost_preds_test = np.column_stack([\n",
    "    models_dict['CatBoost'][target].predict(X_test)\n",
    "    for target in targets\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np = y_test.values.copy()\n",
    "test_accuracy_per_day = []\n",
    "test_precision_per_day = []\n",
    "test_recall_per_day = []\n",
    "\n",
    "ncols = 3\n",
    "nrows = (len(targets) + ncols - 1) // ncols\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 6, nrows * 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for day in range(len(targets)):\n",
    "    w_xgb, w_lgbm, w_cat = best_weights_list[day]\n",
    "    final_preds_test = (\n",
    "        w_xgb  * xgb_preds_test[:, day] +\n",
    "        w_lgbm * lgbm_preds_test[:, day] +\n",
    "        w_cat  * catboost_preds_test[:, day]\n",
    "    )\n",
    "    rounded_preds_test = round_with_thresholds(final_preds_test, thresholds_per_day[day])\n",
    "    \n",
    "    acc = accuracy_score(y_test_np[:, day], rounded_preds_test)\n",
    "    prec = precision_score(y_test_np[:, day], rounded_preds_test, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test_np[:, day], rounded_preds_test, average='weighted', zero_division=0)\n",
    "    print(f\"Day {day}: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}\")\n",
    "    \n",
    "    test_accuracy_per_day.append(acc)\n",
    "    test_precision_per_day.append(prec)\n",
    "    test_recall_per_day.append(rec)\n",
    "    \n",
    "    classes = np.unique(np.concatenate([y_test_np[:, day], rounded_preds_test]))\n",
    "    cm = confusion_matrix(y_test_np[:, day], rounded_preds_test, labels=classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    \n",
    "    ax = axes[day]\n",
    "    disp.plot(ax=ax, cmap='Blues', colorbar=True, xticks_rotation='vertical')\n",
    "    \n",
    "    ax.set_title(f'Confusion Matrix\\nDay {day}')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('True label')\n",
    "\n",
    "for i in range(len(targets), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(models_folder + '/confusion_matrices.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚠️ BELOW CODE IS TO SAVE MODELS, IF UNCOMMENT CAN CAUSE LOST OF PREVIOUS MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(models_folder, exist_ok=True)\n",
    "# np.save(os.path.join(models_folder, 'best_weights.npy'), best_weights_list)\n",
    "# np.save(os.path.join(models_folder, 'thresholds_per_day.npy'), thresholds_per_day)\n",
    "\n",
    "# for model_name in ['XGB', 'LGBM', 'CatBoost']:\n",
    "#     for target in targets:\n",
    "#         model = models_dict[model_name][target]\n",
    "#         model_filename = os.path.join(models_folder, f'{model_name}_{target}_model.pkl')\n",
    "#         joblib.dump(model, model_filename)\n",
    "#         print(f\"Saved {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6986612,
     "sourceId": 11191616,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7032567,
     "sourceId": 11253522,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7032579,
     "sourceId": 11253540,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
